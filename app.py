import os
import json
import re
from typing import Dict, Any, List, Optional
import streamlit as st
import yaml

# --- LLM client libraries ---
from openai import OpenAI
import google.generativeai as genai
from anthropic import Anthropic

# -----------------------------------------------------------
# FDA 510(k) Theme Configuration
# -----------------------------------------------------------

FDA_THEMES = {
    "light": {
        "primary": "#0052CC",
        "secondary": "#00838F",
        "background": "#F7FAFC",
        "text": "#1A202C",
        "accent": "#FF7F50",  # coral for key highlights
    },
    "dark": {
        "primary": "#63B3ED",
        "secondary": "#00B5D8",
        "background": "#1A202C",
        "text": "#E2E8F0",
        "accent": "#FF7F50",  # coral for key highlights
    }
}

REVIEW_CONTEXT_STYLES = {
    "General 510(k)": {
        "icon": "ğŸ“",
        "description": "ä¸€èˆ¬ 510(k) å‚³çµ±é†«ç™‚å™¨æå¯©æŸ¥æƒ…å¢ƒ",
        "color": "#2B6CB0",
    },
    "Orthopedic": {
        "icon": "ğŸ¦´",
        "description": "éª¨ç§‘æ¤å…¥ç‰©èˆ‡å™¨æå¯©æŸ¥æƒ…å¢ƒ",
        "color": "#805AD5",
    },
    "Cardiovascular": {
        "icon": "â¤ï¸",
        "description": "å¿ƒè¡€ç®¡è£ç½®èˆ‡æ”¯æ¶å¯©æŸ¥æƒ…å¢ƒ",
        "color": "#E53E3E",
    },
    "Radiology": {
        "icon": "ğŸ©»",
        "description": "å½±åƒè¨ºæ–·è¨­å‚™èˆ‡ AI è®€ç‰‡è¼”åŠ©å¯©æŸ¥æƒ…å¢ƒ",
        "color": "#3182CE",
    },
    "In Vitro Diagnostic": {
        "icon": "ğŸ§ª",
        "description": "é«”å¤–è¨ºæ–· (IVD) è©¦åŠ‘èˆ‡å„€å™¨å¯©æŸ¥æƒ…å¢ƒ",
        "color": "#38A169",
    },
    "Digital Health": {
        "icon": "ğŸ“±",
        "description": "æ•¸ä½å¥åº·ã€SaMD èˆ‡é è·ç›£æ¸¬ç³»çµ±å¯©æŸ¥æƒ…å¢ƒ",
        "color": "#D53F8C",
    },
    "Surgical": {
        "icon": "ğŸ”ª",
        "description": "æ‰‹è¡“å™¨æ¢°èˆ‡èƒ½é‡è¨­å‚™å¯©æŸ¥æƒ…å¢ƒ",
        "color": "#DD6B20",
    },
    "Dental": {
        "icon": "ğŸ¦·",
        "description": "ç‰™ç§‘è£ç½®èˆ‡ææ–™å¯©æŸ¥æƒ…å¢ƒ",
        "color": "#319795",
    },
    "Anesthesiology": {
        "icon": "ğŸ’¤",
        "description": "éº»é†‰èˆ‡å‘¼å¸æ²»ç™‚è¨­å‚™å¯©æŸ¥æƒ…å¢ƒ",
        "color": "#4A5568",
    },
    "Combination Product": {
        "icon": "ğŸ’Š",
        "description": "è—¥æ¢°çµ„åˆç”¢å“èˆ‡é‚Šç•Œç”¢å“å¯©æŸ¥æƒ…å¢ƒ",
        "color": "#B83280",
    },
}

TRANSLATIONS = {
    "en": {
        "title": "FDA 510(k) Multi-Agent Review Studio",
        "subtitle": "Role: Professional Regulatory AI Orchestrator",
        "theme": "UI Theme",
        "language": "Language",
        "art_style": "Review Context Style",
        "health": "Compliance Health",
        "mana": "AI Resource Capacity",
        "experience": "Case Experience",
        "api_keys": "API Keys",
        "input": "Case Inputs",
        "pipeline": "Review Pipelines",
        "smart_replace": "Smart Editing",
        "notes": "AI Note Keeper",
        "dashboard": "Dashboard",
        "run": "Run Pipeline",
        "level": "Maturity Level",
        "quest_log": "Case Log",
        "achievements": "Milestones",
    },
    "zh": {
        "title": "FDA 510(k) å¤šä»£ç†å¯©æŸ¥å·¥ä½œå®¤",
        "subtitle": "å°ˆæ¥­è§’è‰²ï¼šFDA é†«ç™‚å™¨æ 510(k) å¯©æŸ¥å”ä½œä»£ç†ç³»çµ±",
        "theme": "ä»‹é¢ä¸»é¡Œ",
        "language": "èªè¨€",
        "art_style": "å¯©æŸ¥æƒ…å¢ƒé¢¨æ ¼",
        "health": "åˆè¦å¥åº·åº¦",
        "mana": "AI è³‡æºå®¹é‡",
        "experience": "æ¡ˆä»¶ç¶“é©—å€¼",
        "api_keys": "API é‡‘é‘°",
        "input": "æ¡ˆä»¶è¼¸å…¥",
        "pipeline": "å¯©æŸ¥æµç¨‹",
        "smart_replace": "æ™ºèƒ½ç·¨è¼¯",
        "notes": "AI ç­†è¨˜åŠ©æ‰‹",
        "dashboard": "å„€è¡¨æ¿",
        "run": "åŸ·è¡Œæµç¨‹",
        "level": "å¯©æŸ¥æˆç†Ÿåº¦ç­‰ç´š",
        "quest_log": "æ¡ˆä»¶ç´€éŒ„",
        "achievements": "é‡è¦é‡Œç¨‹ç¢‘",
    }
}

# -----------------------------------------------------------
# Session State Initialization
# -----------------------------------------------------------

def init_session_state():
    """Initialize all session state variables"""
    defaults = {
        "theme": "dark",
        "language": "zh",
        "art_style": "General 510(k)",
        "player_level": 1,
        "health": 100,
        "mana": 100,
        "experience": 0,
        "quests_completed": 0,
        "achievements": [],
        "combat_log": [],
        "template": "## æ¡ˆä»¶æ¨¡æ¿\n\nåœ¨æ­¤æ’°å¯«æˆ–è²¼ä¸Š 510(k) æ¡ˆä»¶ç›¸é—œæ¨¡æ¿å…§å®¹...",
        "observations": "åœ¨æ­¤æ–°å¢è‡¨åºŠã€é¢¨éšªæˆ–æŠ€è¡“è§€å¯Ÿå‚™è¨»...",
        "pipeline_history": [],
        "note_raw_text": "",
        "note_markdown": "",
        "note_formatted": "",
        "note_keywords_output": "",
        "note_entities_json_data": [],
        "note_mindmap_json_text": "",
        "note_wordgraph_json_text": "",
        "note_chat_history": [],
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

# -----------------------------------------------------------
# Utility Functions
# -----------------------------------------------------------

@st.cache_data
def load_agents_config(path: str = "agents.yaml") -> Dict[str, Any]:
    """Load agents configuration from YAML file"""
    try:
        with open(path, "r", encoding="utf-8") as f:
            return yaml.safe_load(f)
    except FileNotFoundError:
        return {"agents": [], "pipelines": []}

def get_translation(key: str) -> str:
    """Get translated text based on current language"""
    lang = st.session_state.get("language", "zh")
    return TRANSLATIONS.get(lang, TRANSLATIONS["zh"]).get(key, key)

def apply_custom_css():
    """Apply FDA 510(k)-themed custom CSS"""
    theme = st.session_state.get("theme", "dark")
    style = st.session_state.get("art_style", "General 510(k)")
    colors = FDA_THEMES[theme]
    accent_color = REVIEW_CONTEXT_STYLES.get(style, REVIEW_CONTEXT_STYLES["General 510(k)"])["color"]
    
    css = f"""
    <style>
    /* Main theme colors */
    .stApp {{
        background-color: {colors['background']};
        color: {colors['text']};
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
    }}
    
    /* Headers */
    h1, h2, h3 {{
        color: {colors['primary']};
        border-bottom: 3px solid {accent_color};
        padding-bottom: 6px;
    }}
    
    /* Buttons */
    .stButton > button {{
        background: linear-gradient(145deg, {accent_color}, {colors['secondary']});
        color: white;
        border: 1px solid {colors['primary']};
        border-radius: 6px;
        font-weight: 600;
        padding: 6px 16px;
        transition: all 0.2s ease;
    }}
    .stButton > button:hover {{
        transform: translateY(-1px);
        box-shadow: 0 4px 10px rgba(0,0,0,0.18);
    }}
    
    /* Status bars container */
    .status-bar {{
        background: linear-gradient(90deg, {accent_color}, transparent);
        border: 1px solid {colors['primary']};
        border-radius: 8px;
        padding: 4px 6px;
        margin: 4px 0;
    }}
    
    /* Card style */
    .review-card {{
        background: {colors['background']};
        border: 2px solid {accent_color};
        border-radius: 10px;
        padding: 14px;
        margin: 6px 0;
        box-shadow: 0 4px 10px rgba(0,0,0,0.15);
    }}
    
    /* Tabs */
    .stTabs [data-baseweb="tab-list"] {{
        gap: 6px;
        background-color: rgba(0,0,0,0.05);
        border-radius: 10px;
        padding: 4px;
    }}
    .stTabs [data-baseweb="tab"] {{
        background-color: {colors['secondary']};
        color: white;
        border-radius: 6px;
        font-weight: 600;
        border: 1px solid {colors['primary']};
    }}
    .stTabs [aria-selected="true"] {{
        background: linear-gradient(145deg, {accent_color}, {colors['primary']});
    }}
    
    /* Input fields */
    .stTextInput > div > div > input,
    .stTextArea > div > div > textarea {{
        background-color: rgba(0,0,0,0.02);
        color: {colors['text']};
        border-radius: 6px;
    }}
    
    /* Sidebar */
    .css-1d391kg {{
        background-color: {colors['background']};
        border-right: 2px solid {accent_color};
    }}
    
    /* Progress bars */
    .stProgress > div > div > div > div {{
        background-color: {accent_color};
    }}
    
    /* Expander header */
    .streamlit-expanderHeader {{
        background-color: {colors['secondary']};
        color: white;
        border-radius: 6px;
        font-weight: 600;
    }}
    </style>
    """
    st.markdown(css, unsafe_allow_html=True)

def update_player_stats(action: str):
    """
    Update abstracted 'player' stats, re-interpreted as review metrics:
    - level: å¯©æŸ¥æˆç†Ÿåº¦ç­‰ç´š
    - health: åˆè¦å¥åº·åº¦
    - mana: AI è³‡æºå®¹é‡
    """
    if action == "quest_complete":
        st.session_state.experience += 10
        st.session_state.quests_completed += 1
        if st.session_state.experience >= st.session_state.player_level * 50:
            st.session_state.player_level += 1
            st.session_state.experience = 0
            st.toast(f"ğŸ¯ å¯©æŸ¥æˆç†Ÿåº¦æå‡ï¼ç›®å‰ç­‰ç´šï¼š{st.session_state.player_level}")
    elif action == "use_mana":
        st.session_state.mana = max(0, st.session_state.mana - 20)
    elif action == "regenerate":
        st.session_state.mana = min(100, st.session_state.mana + 10)
        st.session_state.health = min(100, st.session_state.health + 5)

def add_combat_log(message: str, message_type: str = "info"):
    """Add entry to review activity log"""
    icons = {
        "info": "â„¹ï¸",
        "success": "âœ…",
        "warning": "âš ï¸",
        "error": "âŒ",
        "spell": "ğŸ§ ",
    }
    log_entry = {
        "icon": icons.get(message_type, "â„¹ï¸"),
        "message": message,
        "timestamp": st.session_state.get("quests_completed", 0),
    }
    if "combat_log" not in st.session_state:
        st.session_state.combat_log = []
    st.session_state.combat_log.append(log_entry)
    if len(st.session_state.combat_log) > 50:
        st.session_state.combat_log.pop(0)

# -----------------------------------------------------------
# API Key Management
# -----------------------------------------------------------

def get_api_key_from_env_or_ui(
    provider_name: str,
    env_var: str,
    session_key: str,
    label: str,
) -> Optional[str]:
    """Get API key from environment or user input"""
    env_val = os.getenv(env_var)
    if env_val:
        st.caption(f"ğŸ”‘ {label}: å·²å¾ç’°å¢ƒè®Šæ•¸è¼‰å…¥")
        st.session_state[session_key] = env_val
        return env_val

    key = st.text_input(
        label,
        value=st.session_state.get(session_key, ""),
        type="password",
    )
    if key:
        st.session_state[session_key] = key
        st.caption(f"ğŸ”‘ {label} å·²æš«å­˜æ–¼å·¥ä½œéšæ®µ")
        return key
    return None

# -----------------------------------------------------------
# LLM Call Router
# -----------------------------------------------------------

def call_llm(
    provider: str,
    model: str,
    system_prompt: str,
    user_prompt: str,
    max_tokens: int = 512,
    temperature: float = 0.7,
) -> str:
    """Route LLM calls to appropriate provider"""
    provider = provider.lower().strip()
    
    add_combat_log(f"å‘¼å« {provider} æ¨¡å‹ï¼š{model}", "spell")
    update_player_stats("use_mana")

    if provider == "openai":
        api_key = st.session_state.get("openai_api_key")
        if not api_key:
            raise RuntimeError("OpenAI API key is not set.")
        client = OpenAI(api_key=api_key)
        resp = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            max_tokens=max_tokens,
            temperature=temperature,
        )
        return resp.choices[0].message.content

    elif provider == "gemini":
        api_key = st.session_state.get("gemini_api_key")
        if not api_key:
            raise RuntimeError("Gemini API key is not set.")
        genai.configure(api_key=api_key)
        model_obj = genai.GenerativeModel(model)
        resp = model_obj.generate_content(
            system_prompt + "\n\nUSER MESSAGE:\n" + user_prompt
        )
        return resp.text

    elif provider == "xai":
        api_key = st.session_state.get("xai_api_key")
        if not api_key:
            raise RuntimeError("xAI API key is not set.")
        client = OpenAI(api_key=api_key, base_url="https://api.x.ai/v1")
        resp = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            max_tokens=max_tokens,
            temperature=temperature,
        )
        return resp.choices[0].message.content

    elif provider == "anthropic":
        api_key = st.session_state.get("anthropic_api_key")
        if not api_key:
            raise RuntimeError("Anthropic API key is not set.")
        client = Anthropic(api_key=api_key)
        resp = client.messages.create(
            model=model,
            max_tokens=max_tokens,
            temperature=temperature,
            system=system_prompt,
            messages=[{"role": "user", "content": user_prompt}],
        )
        if resp.content and len(resp.content) > 0:
            block = resp.content[0]
            if hasattr(block, "text"):
                return block.text
        return json.dumps(resp.model_dump(), indent=2)

    else:
        raise ValueError(f"Unsupported provider: {provider}")

def run_agent(
    agent_cfg: Dict[str, Any],
    user_prompt: str,
    override_provider: Optional[str] = None,
    override_model: Optional[str] = None,
    override_system_prompt: Optional[str] = None,
    max_tokens: int = 512,
    temperature: float = 0.7,
) -> str:
    """Run a single configured agent"""
    provider = override_provider or agent_cfg.get("provider", "openai")
    model = override_model or agent_cfg.get("default_model", "gpt-4o-mini")
    system_prompt = override_system_prompt or agent_cfg.get("system_prompt", "")
    return call_llm(
        provider=provider,
        model=model,
        system_prompt=system_prompt,
        user_prompt=user_prompt,
        max_tokens=max_tokens,
        temperature=temperature,
    )

# -----------------------------------------------------------
# Status Indicators
# -----------------------------------------------------------

def render_status_indicators():
    """Render review status indicators"""
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown(f"### {get_translation('level')} {st.session_state.player_level}")
        
    with col2:
        st.markdown(f"### {get_translation('health')}")
        st.progress(st.session_state.health / 100)
        st.caption(f"{st.session_state.health}/100")
        
    with col3:
        st.markdown(f"### {get_translation('mana')}")
        st.progress(st.session_state.mana / 100)
        st.caption(f"{st.session_state.mana}/100")
        
    with col4:
        st.markdown(f"### {get_translation('experience')}")
        max_xp = st.session_state.player_level * 50
        st.progress(st.session_state.experience / max_xp)
        st.caption(f"{st.session_state.experience}/{max_xp}")

def render_activity_log():
    """Render review activity log"""
    st.markdown("### ğŸ“‘ æ´»å‹•ç´€éŒ„")
    with st.expander("æª¢è¦–è¿‘æœŸå‹•ä½œ", expanded=False):
        if st.session_state.combat_log:
            for entry in reversed(st.session_state.combat_log[-20:]):
                st.markdown(f"{entry['icon']} {entry['message']}")
        else:
            st.info("ç›®å‰å°šç„¡æ´»å‹•ç´€éŒ„")

# -----------------------------------------------------------
# Review Context Selector
# -----------------------------------------------------------

def render_review_context_selector():
    """Render interactive review context selector"""
    st.markdown("### ğŸ¥ å¯©æŸ¥æƒ…å¢ƒé¸æ“‡å™¨")
    
    cols = st.columns(5)
    styles = list(REVIEW_CONTEXT_STYLES.keys())
    
    for idx, style in enumerate(styles):
        with cols[idx % 5]:
            style_data = REVIEW_CONTEXT_STYLES[style]
            button_label = f"{style_data['icon']} {style}"
            
            if st.button(
                button_label,
                key=f"style_{style}",
                help=style_data["description"],
                use_container_width=True
            ):
                st.session_state.art_style = style
                add_combat_log(f"åˆ‡æ›å¯©æŸ¥æƒ…å¢ƒç‚ºï¼š{style}", "success")
                st.rerun()
    
    current_style = st.session_state.get("art_style", "General 510(k)")
    style_data = REVIEW_CONTEXT_STYLES[current_style]
    st.markdown(
        f"<div class='review-card' style='text-align: center; "
        f"background: linear-gradient(145deg, {style_data['color']}, transparent);'>"
        f"<h3>{style_data['icon']} ç›®å‰æƒ…å¢ƒï¼š{current_style}</h3>"
        f"<p>{style_data['description']}</p>"
        f"</div>",
        unsafe_allow_html=True
    )

# -----------------------------------------------------------
# Enhanced Sidebar
# -----------------------------------------------------------

def render_enhanced_sidebar(config: Dict[str, Any]):
    """Render FDA 510(k)-themed sidebar with controls"""
    st.sidebar.markdown(f"# {get_translation('title')}")
    st.sidebar.markdown(f"*{get_translation('subtitle')}*")
    
    st.sidebar.markdown("---")
    
    # Theme and Language Selection
    col1, col2 = st.sidebar.columns(2)
    with col1:
        theme = st.selectbox(
            get_translation("theme"),
            ["light", "dark"],
            index=1 if st.session_state.theme == "dark" else 0,
            key="theme_selector"
        )
        if theme != st.session_state.theme:
            st.session_state.theme = theme
            st.rerun()
    
    with col2:
        lang = st.selectbox(
            get_translation("language"),
            ["zh", "en"],
            index=0 if st.session_state.language == "zh" else 1,
            key="lang_selector"
        )
        if lang != st.session_state.language:
            st.session_state.language = lang
            st.rerun()
    
    st.sidebar.markdown("---")
    
    # Review Status
    st.sidebar.markdown("### ğŸ“Š å¯©æŸ¥ç‹€æ…‹ç¸½è¦½")
    render_status_indicators()
    
    st.sidebar.markdown("---")
    
    # API Keys
    st.sidebar.markdown(f"### ğŸ”‘ {get_translation('api_keys')}")
    
    with st.sidebar.expander("è¨­å®š API é‡‘é‘°"):
        get_api_key_from_env_or_ui(
            "OpenAI", "OPENAI_API_KEY", "openai_api_key", "OpenAI API Key"
        )
        get_api_key_from_env_or_ui(
            "Gemini", "GEMINI_API_KEY", "gemini_api_key", "Gemini API Key"
        )
        get_api_key_from_env_or_ui(
            "xAI", "XAI_API_KEY", "xai_api_key", "xAI (Grok) API Key"
        )
        get_api_key_from_env_or_ui(
            "Anthropic", "ANTHROPIC_API_KEY", "anthropic_api_key", "Anthropic API Key"
        )
    
    st.sidebar.markdown("---")
    
    # Model Settings
    st.sidebar.markdown("### âš™ï¸ æ¨¡å‹å‘¼å«è¨­å®š")
    
    provider = st.sidebar.selectbox(
        "æ¨¡å‹ä¾›æ‡‰å•†",
        ["openai", "gemini", "xai", "anthropic"],
        key="default_provider",
    )
    
    provider_models = {
        "openai": ["gpt-4o-mini", "gpt-4.1-mini"],
        "gemini": ["gemini-2.5-flash", "gemini-2.5-flash-lite"],
        "xai": ["grok-4-fast-reasoning", "grok-3-mini"],
        "anthropic": ["claude-3-5-sonnet-latest", "claude-3-opus-latest"],
    }
    
    st.sidebar.selectbox(
        "æ¨¡å‹ç‰ˆæœ¬",
        provider_models[provider],
        key="default_model",
    )
    
    st.sidebar.slider(
        "æœ€å¤§è¼¸å‡º Token æ•¸",
        64, 4096, 1024, 64,
        key="default_max_tokens",
    )
    
    st.sidebar.slider(
        "æº«åº¦ï¼ˆéš¨æ©Ÿæ€§ï¼‰",
        0.0, 1.0, 0.7, 0.05,
        key="default_temperature",
    )
    
    st.sidebar.markdown("---")
    
    # Case Log
    st.sidebar.markdown(f"### ğŸ“ {get_translation('quest_log')}")
    st.sidebar.metric("å·²å®Œæˆæ¡ˆä»¶æ•¸", st.session_state.quests_completed)
    
    if st.sidebar.button("ğŸ”„ æ¢å¾©è³‡æº"):
        update_player_stats("regenerate")
        add_combat_log("AI è³‡æºèˆ‡åˆè¦å¥åº·åº¦å·²é©åº¦æ¢å¾©", "success")
        st.rerun()

# -----------------------------------------------------------
# Input Tab
# -----------------------------------------------------------

def render_input_tab():
    """Render case input tab"""
    st.markdown(f"## ğŸ“ {get_translation('input')}")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.text_area(
            "ğŸ“„ 510(k) æ¡ˆä»¶æ¨¡æ¿ / ä¸»è¦å…§å®¹",
            key="template",
            height=260,
            help="ä¾‹å¦‚ï¼šè¨­å‚™æè¿°ã€é©æ‡‰ç—‡èªªæ˜ã€å¯¦è³ªç­‰åŒæ€§æ¯”è¼ƒã€é¢¨éšªç®¡ç†æ‘˜è¦ç­‰"
        )
        
        st.text_area(
            "ğŸ” å¯©æŸ¥è§€å¯Ÿèˆ‡å‚™è¨»",
            key="observations",
            height=260,
            help="è¨˜éŒ„å¯©æŸ¥æ­·ç¨‹ä¸­çš„ç–‘å•ã€é¢¨éšªé»ã€éœ€è¿½å•ä¹‹è³‡æ–™ç­‰"
        )
    
    with col2:
        render_activity_log()
        
        st.markdown("### âš¡ å¿«é€Ÿå‹•ä½œ")
        if st.button("ğŸ’¾ å„²å­˜ç•¶å‰è¼¸å…¥", use_container_width=True):
            add_combat_log("ç›®å‰æ¡ˆä»¶è¼¸å…¥å·²å„²å­˜ï¼ˆæš«å­˜æ–¼ sessionï¼‰", "success")
            st.success("å·²æš«å­˜ç›®å‰å…§å®¹ã€‚")
        
        if st.button("ğŸ§¹ æ¸…ç©ºæ¬„ä½", use_container_width=True):
            st.session_state.template = ""
            st.session_state.observations = ""
            add_combat_log("æ¡ˆä»¶è¼¸å…¥æ¬„ä½å·²æ¸…ç©º", "info")
            st.rerun()

# -----------------------------------------------------------
# Pipeline Tab
# -----------------------------------------------------------

def render_pipeline_tab(config: Dict[str, Any]):
    """Render multi-agent 510(k) review pipeline tab"""
    st.markdown(f"## ğŸ”„ {get_translation('pipeline')}")
    
    if not config or "pipelines" not in config:
        st.warning("âš ï¸ agents.yaml ä¸­æœªæ‰¾åˆ°ä»»ä½•å¯©æŸ¥æµç¨‹ (pipelines) è¨­å®šã€‚")
        return
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        pipeline_options = {p["name"]: p for p in config["pipelines"]}
        selected_name = st.selectbox("ğŸ” é¸æ“‡å¯©æŸ¥æµç¨‹", list(pipeline_options.keys()))
        pipeline = pipeline_options[selected_name]
        
        st.markdown(f"**æµç¨‹ IDï¼š** `{pipeline['id']}`")
        st.markdown(f"**èªªæ˜ï¼š** {pipeline.get('description', '')}")
        
        st.markdown("### ğŸ“‚ æµç¨‹æ­¥é©Ÿ")
        for idx, step in enumerate(pipeline["steps"], start=1):
            st.markdown(f"- ç¬¬ {idx} æ­¥ï¼š`{step['agent_id']}`")
        
        st.markdown("---")
        
        override_prompt = st.text_area(
            "ğŸ“Œ å…¶ä»–è£œå……èªªæ˜ / ç‰¹åˆ¥æŒ‡ç¤º",
            "ä¾‹å¦‚ï¼šæ­¤æ¡ˆä»¶é¢¨éšªåé«˜ï¼Œè«‹æé«˜é¢¨éšªè©•ä¼°èˆ‡æ³•è¦æ¯”å°çš„åš´è¬¹åº¦ã€‚",
            height=120,
        )
        
        col_a, col_b = st.columns(2)
        with col_a:
            provider = st.selectbox(
                "æ¨¡å‹ä¾›æ‡‰å•†è¦†å¯«ï¼ˆé¸å¡«ï¼‰",
                ["(ä½¿ç”¨é è¨­)", "openai", "gemini", "xai", "anthropic"],
            )
        with col_b:
            model_override = st.text_input("æ¨¡å‹åç¨±è¦†å¯«ï¼ˆé¸å¡«ï¼‰", "")
        
        if st.button(f"â–¶ï¸ {get_translation('run')}", use_container_width=True):
            if st.session_state.mana < 20:
                st.error("âŒ AI è³‡æºä¸è¶³ï¼Œè«‹å…ˆæŒ‰å·¦å´ã€æ¢å¾©è³‡æºã€ã€‚")
                return
            
            template = st.session_state.get("template", "")
            observations = st.session_state.get("observations", "")
            current_input = (
                "ã€510(k) æ¡ˆä»¶è¼¸å…¥ã€‘\n"
                f"{template}\n\n"
                "ã€å¯©æŸ¥è§€å¯Ÿèˆ‡å‚™è¨»ã€‘\n"
                f"{observations}\n\n"
                "ã€é¡å¤–æŒ‡ç¤ºã€‘\n"
                f"{override_prompt}"
            )
            
            outputs = []
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            for idx, step in enumerate(pipeline["steps"]):
                agent_id = step["agent_id"]
                agent_cfg = next((a for a in config["agents"] if a["id"] == agent_id), None)
                
                if not agent_cfg:
                    st.error(f"âŒ æ‰¾ä¸åˆ°ä»£ç†è¨­å®šï¼š{agent_id}")
                    return
                
                progress = (idx + 1) / len(pipeline["steps"])
                progress_bar.progress(progress)
                status_text.text(f"åŸ·è¡Œä»£ç†ï¼š{agent_cfg['name']} ...")
                
                try:
                    result = run_agent(
                        agent_cfg=agent_cfg,
                        user_prompt=current_input,
                        override_provider=None if provider.startswith("(") else provider,
                        override_model=model_override or None,
                        max_tokens=st.session_state.get("default_max_tokens", 1024),
                        temperature=st.session_state.get("default_temperature", 0.7),
                    )
                    outputs.append({"agent_id": agent_id, "output": result})
                    current_input = result
                    update_player_stats("regenerate")
                except Exception as e:
                    st.error(f"âŒ æ¨¡å‹å‘¼å«å¤±æ•—ï¼š{e}")
                    add_combat_log(f"å¯©æŸ¥æµç¨‹åœ¨ä»£ç† {agent_id} ä¸­æ–·ã€‚", "error")
                    return
            
            progress_bar.progress(1.0)
            status_text.text("âœ… å¯©æŸ¥æµç¨‹å®Œæˆã€‚")
            
            st.success("ğŸ‰ å¯©æŸ¥æµç¨‹å·²æˆåŠŸå®Œæˆä¸¦ç”¢å‡ºçµæœã€‚")
            update_player_stats("quest_complete")
            add_combat_log(f"å·²å®Œæˆå¯©æŸ¥æµç¨‹ï¼š{selected_name}", "success")
            
            st.session_state.pipeline_history.append(outputs)
            
            st.markdown("### ğŸ“˜ æµç¨‹è¼¸å‡ºçµæœ")
            for idx, item in enumerate(outputs, start=1):
                with st.expander(f"æ­¥é©Ÿ {idx} â€“ ä»£ç† `{item['agent_id']}`", expanded=(idx == len(outputs))):
                    st.markdown(item["output"])
    
    with col2:
        render_activity_log()
        st.markdown("### ğŸ“Š æµç¨‹çµ±è¨ˆ")
        st.metric("å·²åŸ·è¡Œæµç¨‹æ¬¡æ•¸", len(st.session_state.pipeline_history))

# -----------------------------------------------------------
# Smart Replace Tab (placeholder, original feature kept)
# -----------------------------------------------------------

def render_smart_replace_tab():
    """Placeholder for smart editing (original feature kept)"""
    st.markdown(f"## âœ¨ {get_translation('smart_replace')}")
    st.info("æ­¤å€å¯æ•´åˆæ—¢æœ‰æ–‡å­—æ”¹å¯«èˆ‡æ¯”å°å·¥å…·ï¼ˆä¿ç•™åŸå§‹è¨­è¨ˆç©ºé–“ï¼‰ã€‚")

# -----------------------------------------------------------
# AI Note Keeper: helpers
# -----------------------------------------------------------

def highlight_keywords_in_text(text: str, keywords: List[str], color: str) -> str:
    """Highlight given keywords in text using HTML span with specified color"""
    if not text or not keywords:
        return text
    result = text
    for kw in keywords:
        kw = kw.strip()
        if not kw:
            continue
        pattern = re.compile(re.escape(kw), re.IGNORECASE)
        result = pattern.sub(
            lambda m: f"<span style='color:{color}'>{m.group(0)}</span>",
            result,
        )
    return result

# -----------------------------------------------------------
# AI Note Keeper Tab
# -----------------------------------------------------------

def render_notes_tab():
    """Render AI Note Keeper with multiple AI tools"""
    st.markdown(f"## ğŸ“” {get_translation('notes')}")
    st.info(
        "å°‡ 510(k) æˆ–é†«ç™‚å™¨æç›¸é—œæ–‡å­—è²¼ä¸Šï¼Œåˆ©ç”¨å¤šä»£ç† AI é€²è¡Œ **Markdown çµæ§‹åŒ–ã€æ ¼å¼å„ªåŒ–ã€é—œéµå­—æ¨™ç¤ºã€å¯¦é«”æŠ½å–ã€å¿ƒæ™ºåœ–èˆ‡è©å½™é—œè¯åœ–**ã€‚"
    )
    
    col1, col2 = st.columns([2, 1])
    with col1:
        st.text_area(
            "ğŸ§¾ åŸå§‹æ–‡æœ¬è²¼ä¸Šå€",
            key="note_raw_text",
            height=260,
            help="ä¾‹å¦‚ï¼š510(k) æ‘˜è¦ã€é¢¨éšªç®¡ç†å ±å‘Šç‰‡æ®µã€æŠ€è¡“èªªæ˜ã€å›è¦† FDA å•ç­”ç­‰",
        )
        if st.button("ğŸ“„ è½‰æ›ç‚º Markdown çµæ§‹", use_container_width=True):
            if not st.session_state.note_raw_text.strip():
                st.warning("è«‹å…ˆè²¼ä¸ŠåŸå§‹æ–‡æœ¬ã€‚")
            else:
                try:
                    provider = st.session_state.get("default_provider", "openai")
                    model = st.session_state.get("default_model", "gpt-4o-mini")
                    system_prompt = (
                        "ä½ æ˜¯ä¸€åå°ˆæ¥­çš„ FDA é†«ç™‚å™¨æ 510(k) å¯©æŸ¥ç­†è¨˜æ•´ç†åŠ©ç†ï¼Œ"
                        "è«‹å°‡ä½¿ç”¨è€…æä¾›çš„åŸå§‹æ–‡å­—è½‰æ›ç‚º **çµæ§‹æ¸…æ¥šçš„ Markdown æ–‡ä»¶**ï¼Œ"
                        "è¦æ±‚ï¼š\n"
                        "1. åš´æ ¼ä¿ç•™æ‰€æœ‰åŸå§‹è³‡è¨Šå…§å®¹ï¼ˆä¸åˆªæ¸›ã€ä¸æ”¹å¯«å¯¦è³ªæ„ç¾©ï¼‰ã€‚\n"
                        "2. å…è¨±é‡æ–°åˆ†æ®µã€åŠ å…¥æ¨™é¡Œéšå±¤ (##, ###) èˆ‡æ¢åˆ—é»ï¼Œä½¿å…§å®¹æ›´æ˜“è®€ã€‚\n"
                        "3. ä¸è¦åŠ å…¥ä»»ä½•å¤šé¤˜èªªæ˜ï¼Œåªè¼¸å‡º Markdown å…§å®¹æœ¬èº«ã€‚"
                    )
                    user_prompt = st.session_state.note_raw_text
                    md = call_llm(
                        provider=provider,
                        model=model,
                        system_prompt=system_prompt,
                        user_prompt=user_prompt,
                        max_tokens=st.session_state.get("default_max_tokens", 1024),
                        temperature=0.1,
                    )
                    st.session_state.note_markdown = md
                    add_combat_log("å®ŒæˆåŸå§‹æ–‡æœ¬çš„ Markdown çµæ§‹åŒ–ã€‚", "success")
                except Exception as e:
                    st.error(f"è½‰æ›ç‚º Markdown æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
    
    with col2:
        st.markdown("### ğŸ“‘ Markdown é è¦½")
        if st.session_state.note_markdown:
            st.markdown(st.session_state.note_markdown)
        else:
            st.caption("å°šæœªç”¢ç”Ÿ Markdownï¼Œè«‹å…ˆæ–¼å·¦å´è²¼ä¸Šæ–‡å­—ä¸¦æŒ‰ä¸‹ã€Œè½‰æ›ç‚º Markdownã€ã€‚")
    
    st.markdown("---")
    
    tab_fmt, tab_kw, tab_ent, tab_mind, tab_word = st.tabs(
        ["AI æ ¼å¼å„ªåŒ–", "AI é—œéµå­—æ¨™ç¤º", "AI å¯¦é«”æŠ½å–", "AI å¿ƒæ™ºåœ–", "AI è©å½™é—œè¯åœ–"]
    )
    
    # --- AI Formatting ---
    with tab_fmt:
        st.markdown("### ğŸ§¹ AI æ ¼å¼å„ªåŒ–ï¼ˆä¿ç•™åŸæ–‡ï¼Œå¼·åŒ–çµæ§‹èˆ‡é‡é»ï¼‰")
        st.caption(
            "èªªæ˜ï¼šåœ¨**ä¸åˆªé™¤ä»»ä½•åŸæ–‡å¥å­**çš„å‰æä¸‹ï¼Œé‡æ–°ç·¨æ’æ®µè½èˆ‡æ¨™é¡Œï¼Œä¸¦ç”¨çŠç‘šè‰²æ¨™è¨»é‡è¦è¡“èªã€‚"
        )
        if st.button("âš™ï¸ åŸ·è¡Œ AI æ ¼å¼å„ªåŒ–", use_container_width=True, key="btn_ai_format"):
            base_text = st.session_state.note_markdown or st.session_state.note_raw_text
            if not base_text.strip():
                st.warning("è«‹å…ˆè²¼ä¸Šæ–‡å­—ä¸¦è‡³å°‘å®Œæˆä¸€æ¬¡ Markdown è½‰æ›ã€‚")
            else:
                try:
                    provider = st.session_state.get("default_provider", "openai")
                    model = st.session_state.get("default_model", "gpt-4o-mini")
                    system_prompt = (
                        "ä½ æ˜¯ä¸€å FDA 510(k) å°ˆæ¥­å¯©æŸ¥æ–‡ä»¶ç·¨è¼¯åŠ©ç†ã€‚è«‹å°ä½¿ç”¨è€…æä¾›çš„æ–‡å­—é€²è¡Œï¼š\n"
                        "1. åš´æ ¼ä¿ç•™æ‰€æœ‰åŸå§‹å¥å­å…§å®¹ï¼Œä¸åˆªé™¤ä»»ä½•å¥å­ã€‚\n"
                        "2. å…è¨±é‡æ–°æ’åºæ®µè½ã€åˆ†ç¾¤ä¸»é¡Œã€åŠ å…¥é©ç•¶ Markdown æ¨™é¡Œ (##, ###)ã€‚\n"
                        "3. é‡å°é‡è¦æ³•è¦ã€æŠ€è¡“ã€é¢¨éšªèˆ‡è‡¨åºŠç›¸é—œé—œéµè©ï¼Œä»¥ "
                        "<span style=\"color:coral\">...é—œéµè©...</span> çš„ HTML span å½¢å¼æ¨™ç¤ºï¼ˆåƒ…æ”¹è®Šå‘ˆç¾ï¼Œä¸æ”¹è®Šæ–‡å­—ï¼‰ã€‚\n"
                        "4. åƒ…è¼¸å‡º Markdown + HTML span æ ¼å¼ï¼Œä¸è¦é¡å¤–è§£é‡‹ã€‚"
                    )
                    user_prompt = base_text
                    formatted = call_llm(
                        provider=provider,
                        model=model,
                        system_prompt=system_prompt,
                        user_prompt=user_prompt,
                        max_tokens=st.session_state.get("default_max_tokens", 2048),
                        temperature=0.4,
                    )
                    st.session_state.note_formatted = formatted
                    add_combat_log("å®Œæˆ AI æ ¼å¼å„ªåŒ–èˆ‡é‡é»æ¨™ç¤ºã€‚", "success")
                except Exception as e:
                    st.error(f"AI æ ¼å¼å„ªåŒ–å¤±æ•—ï¼š{e}")
        
        if st.session_state.note_formatted:
            st.markdown("#### æ ¼å¼å„ªåŒ–çµæœ")
            st.markdown(st.session_state.note_formatted, unsafe_allow_html=True)
    
    # --- AI Keywords ---
    with tab_kw:
        st.markdown("### ğŸ¯ AI é—œéµå­—æ¨™ç¤º")
        st.caption("å¯è‡ªè¨‚æ¬²å¼·èª¿çš„é—œéµè©èˆ‡é¡è‰²ï¼Œåœ¨ Markdown å…§å®¹ä¸­è‡ªå‹•é«˜äº®ã€‚")
        
        kw_text = st.text_input(
            "è¼¸å…¥æ¬²æ¨™ç¤ºçš„é—œéµå­—ï¼ˆä»¥é€—è™Ÿåˆ†éš”ï¼‰",
            value="510(k), å¯¦è³ªç­‰åŒæ€§, é¢¨éšªç®¡ç†, æ€§èƒ½æ¸¬è©¦, FDA",
        )
        kw_color = st.color_picker("é—œéµå­—é¡è‰²", value="#FF7F50")
        
        if st.button("ğŸ” æ¨™ç¤ºé—œéµå­—", use_container_width=True):
            base_text = (
                st.session_state.note_formatted
                or st.session_state.note_markdown
                or st.session_state.note_raw_text
            )
            if not base_text.strip():
                st.warning("å°šç„¡å¯è™•ç†çš„æ–‡æœ¬ï¼Œè«‹å…ˆç”¢ç”Ÿ Markdown æˆ–è²¼ä¸Šæ–‡å­—ã€‚")
            else:
                keywords = [k for k in kw_text.split(",") if k.strip()]
                highlighted = highlight_keywords_in_text(base_text, keywords, kw_color)
                st.session_state.note_keywords_output = highlighted
                add_combat_log("å®Œæˆè‡ªè¨‚é—œéµå­—æ¨™ç¤ºã€‚", "success")
        
        if st.session_state.note_keywords_output:
            st.markdown("#### é—œéµå­—æ¨™ç¤ºçµæœ")
            st.markdown(st.session_state.note_keywords_output, unsafe_allow_html=True)
    
    # --- AI Entities ---
    with tab_ent:
        st.markdown("### ğŸ§¬ AI å¯¦é«”æŠ½å–ï¼ˆæœ€å¤š 20 å€‹ï¼‰")
        st.caption(
            "å¾æ–‡æœ¬ä¸­æŠ½å–æœ€é‡è¦çš„æ³•è¦ã€æŠ€è¡“ã€è‡¨åºŠèˆ‡é¢¨éšªç›¸é—œå¯¦é«”ï¼Œä¸¦ç”¢ç”Ÿçµæ§‹åŒ–è¡¨æ ¼èˆ‡ JSONã€‚"
        )
        if st.button("ğŸ“Š æŠ½å– 20 å€‹é—œéµå¯¦é«”", use_container_width=True):
            base_text = st.session_state.note_markdown or st.session_state.note_raw_text
            if not base_text.strip():
                st.warning("è«‹å…ˆè²¼ä¸Šæ–‡å­—ä¸¦è‡³å°‘å®Œæˆä¸€æ¬¡ Markdown è½‰æ›ã€‚")
            else:
                try:
                    provider = st.session_state.get("default_provider", "openai")
                    model = st.session_state.get("default_model", "gpt-4o-mini")
                    system_prompt = (
                        "ä½ æ˜¯ä¸€å FDA 510(k) å¯©æŸ¥è³‡è¨ŠæŠ½å–å°ˆå®¶ã€‚"
                        "è«‹å¾ä½¿ç”¨è€…æä¾›çš„æ–‡å­—ä¸­ï¼Œé¸å‡º **æœ€å¤š 20 å€‹æœ€é—œéµçš„å¯¦é«” (entity)**ï¼Œ"
                        "å¯¦é«”å¯ä»¥æ˜¯ï¼šæ³•è¦æ¢æ–‡ã€æ¨™æº–ã€æ–‡ä»¶å€æ®µï¼ˆå¦‚ Indications for Useï¼‰ã€"
                        "è¨­å‚™æ¨¡çµ„ã€é¢¨éšªé¡åˆ¥ã€æ€§èƒ½æ¸¬è©¦é …ç›®ã€è‡¨åºŠç«¯é»ç­‰ã€‚\n\n"
                        "è«‹**åªè¼¸å‡º JSON**ï¼Œæ ¼å¼ç‚ºï¼š\n"
                        "[\n"
                        "  {{\"id\": 1, \"name\": \"...\", \"type\": \"regulation|section|risk|test|clinical|other\", "
                        "\"description\": \"ç°¡æ½”èªªæ˜\", \"source_snippet\": \"åŸæ–‡ä¸­çš„ä»£è¡¨æ€§ç‰‡æ®µ\"}},\n"
                        "  ... å…±æœ€å¤š 20 ç­†\n"
                        "]\n"
                        "ä¸è¦è¼¸å‡ºä»»ä½•é¡å¤–æ–‡å­—ã€‚"
                    )
                    user_prompt = base_text
                    raw = call_llm(
                        provider=provider,
                        model=model,
                        system_prompt=system_prompt,
                        user_prompt=user_prompt,
                        max_tokens=1024,
                        temperature=0.2,
                    )
                    # å˜—è©¦è§£æ JSON
                    raw_str = raw.strip().strip("```json").strip("```").strip()
                    entities = json.loads(raw_str)
                    if not isinstance(entities, list):
                        raise ValueError("å›å‚³å…§å®¹ä¸¦é JSON é™£åˆ—ã€‚")
                    st.session_state.note_entities_json_data = entities
                    add_combat_log("å®Œæˆæ–‡æœ¬å¯¦é«”æŠ½å–ï¼ˆæœ€å¤š 20 å€‹ï¼‰ã€‚", "success")
                except Exception as e:
                    st.error(f"å¯¦é«”æŠ½å–èˆ‡ JSON è§£æå¤±æ•—ï¼š{e}")
        
        if st.session_state.note_entities_json_data:
            st.markdown("#### å¯¦é«”è¡¨æ ¼")
            # å»ºç«‹ Markdown è¡¨æ ¼
            table_md = "| id | name | type | description | source_snippet |\n"
            table_md += "|---|------|------|-------------|----------------|\n"
            for ent in st.session_state.note_entities_json_data:
                table_md += (
                    f"| {ent.get('id','')} "
                    f"| {ent.get('name','')} "
                    f"| {ent.get('type','')} "
                    f"| {ent.get('description','').replace('|','/')} "
                    f"| {ent.get('source_snippet','').replace('|','/')} |\n"
                )
            st.markdown(table_md)
            
            st.markdown("#### JSON æª¢è¦–")
            st.json(st.session_state.note_entities_json_data)
    
    # --- AI Mind-Map ---
    with tab_mind:
        st.markdown("### ğŸ§  AI å¿ƒæ™ºåœ–")
        st.caption(
            "æ ¹æ“šæ–‡æœ¬å…§å®¹è‡ªå‹•ç”¢ç”Ÿç¯€é»èˆ‡é—œä¿‚çš„ JSONï¼Œæ‚¨å¯æ‰‹å‹•èª¿æ•´å¾Œï¼Œå³æ™‚è¦–è¦ºåŒ–ç‚ºå¿ƒæ™ºåœ–ã€‚"
        )
        if st.button("ğŸ§  ç”¢ç”Ÿå¿ƒæ™ºåœ– JSON", use_container_width=True):
            base_text = st.session_state.note_markdown or st.session_state.note_raw_text
            if not base_text.strip():
                st.warning("è«‹å…ˆè²¼ä¸Šæ–‡å­—ä¸¦è‡³å°‘å®Œæˆä¸€æ¬¡ Markdown è½‰æ›ã€‚")
            else:
                try:
                    provider = st.session_state.get("default_provider", "openai")
                    model = st.session_state.get("default_model", "gpt-4o-mini")
                    system_prompt = (
                        "ä½ æ˜¯ä¸€åçŸ¥è­˜åœ–è­œè¨­è¨ˆåŠ©ç†ã€‚è«‹æ ¹æ“šä½¿ç”¨è€…æä¾›çš„æ–‡å­—å…§å®¹ï¼Œ"
                        "å»ºç«‹ä¸€ä»½ç°¡æ½”çš„ **å¿ƒæ™ºåœ–çµæ§‹ JSON**ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š\n"
                        "{\n"
                        "  \"nodes\": [\n"
                        "    {\"id\": \"NodeID\", \"label\": \"é¡¯ç¤ºåç¨±\", \"type\": \"device|risk|test|regulation|clinical|other\"},\n"
                        "    ...\n"
                        "  ],\n"
                        "  \"edges\": [\n"
                        "    {\"source\": \"NodeID\", \"target\": \"NodeID\", \"relation\": \"æ–‡å­—æè¿°æ­¤é—œä¿‚\"},\n"
                        "    ...\n"
                        "  ]\n"
                        "}\n"
                        "è«‹å°‡ç¯€é»æ•¸æ§åˆ¶åœ¨ 8â€“15 å€‹ä¹‹é–“ï¼Œé‚Šæ•¸ 10â€“25 å€‹ä¹‹é–“ã€‚åªè¼¸å‡º JSONï¼Œä¸è¦é¡å¤–æ–‡å­—ã€‚"
                    )
                    user_prompt = base_text
                    raw = call_llm(
                        provider=provider,
                        model=model,
                        system_prompt=system_prompt,
                        user_prompt=user_prompt,
                        max_tokens=1024,
                        temperature=0.3,
                    )
                    raw_str = raw.strip().strip("```json").strip("```").strip()
                    # åƒ…å­˜æ–‡å­—ï¼Œç”±ä½¿ç”¨è€…å¯å†ä¿®æ”¹
                    st.session_state.note_mindmap_json_text = raw_str
                    add_combat_log("å·²ç”¢ç”Ÿå¿ƒæ™ºåœ– JSON çµæ§‹ã€‚", "success")
                except Exception as e:
                    st.error(f"å¿ƒæ™ºåœ– JSON ç”¢ç”Ÿå¤±æ•—ï¼š{e}")
        
        mindmap_text = st.text_area(
            "å¿ƒæ™ºåœ– JSON å¯æ–¼æ­¤èª¿æ•´å¾Œé‡æ–°ç¹ªè£½",
            value=st.session_state.note_mindmap_json_text,
            height=220,
        )
        if st.button("ğŸ“ˆ æ ¹æ“š JSON é¡¯ç¤ºå¿ƒæ™ºåœ–", use_container_width=True):
            try:
                data = json.loads(mindmap_text)
                nodes = data.get("nodes", [])
                edges = data.get("edges", [])
                dot = "digraph G {\nrankdir=LR;\n"
                # ç¯€é»
                for n in nodes:
                    nid = n.get("id", "")
                    label = n.get("label", nid)
                    dot += f"  \"{nid}\" [label=\"{label}\"];\n"
                # é‚Š
                for e in edges:
                    src = e.get("source", "")
                    tgt = e.get("target", "")
                    rel = e.get("relation", "")
                    dot += f"  \"{src}\" -> \"{tgt}\" [label=\"{rel}\"];\n"
                dot += "}"
                st.graphviz_chart(dot)
            except Exception as e:
                st.error(f"è§£ææˆ–ç¹ªè£½å¿ƒæ™ºåœ–æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
    
    # --- AI Wordgraph ---
    with tab_word:
        st.markdown("### ğŸ“š AI è©å½™é—œè¯åœ– (Wordgraph)")
        st.caption(
            "æ ¹æ“šæ–‡æœ¬è‡ªå‹•åˆ†æé‡è¦è¡“èªä¹‹é–“çš„é—œè¯ï¼Œç”¢ç”Ÿè©å½™é—œè¯åœ– JSON ä¸¦è¦–è¦ºåŒ–ã€‚"
        )
        if st.button("ğŸ“š ç”¢ç”Ÿè©å½™é—œè¯ JSON", use_container_width=True):
            base_text = st.session_state.note_markdown or st.session_state.note_raw_text
            if not base_text.strip():
                st.warning("è«‹å…ˆè²¼ä¸Šæ–‡å­—ä¸¦è‡³å°‘å®Œæˆä¸€æ¬¡ Markdown è½‰æ›ã€‚")
            else:
                try:
                    provider = st.session_state.get("default_provider", "openai")
                    model = st.session_state.get("default_model", "gpt-4o-mini")
                    system_prompt = (
                        "ä½ æ˜¯ä¸€åæ–‡å­—æ¢å‹˜èˆ‡çŸ¥è­˜åœ–è­œå°ˆå®¶ã€‚è«‹å¾ä½¿ç”¨è€…æä¾›çš„æ–‡æœ¬ä¸­ï¼Œ"
                        "æ‰¾å‡ºæœ€é‡è¦çš„ 10â€“15 å€‹æŠ€è¡“ï¼æ³•è¦ï¼è‡¨åºŠè¡“èªï¼Œä¸¦å»ºç«‹è©å½™é—œè¯åœ– JSONï¼š\n"
                        "{\n"
                        "  \"nodes\": [\n"
                        "    {\"id\": \"TermID\", \"label\": \"é¡¯ç¤ºåç¨±\", \"frequency\": æ•¸å­—},\n"
                        "    ...\n"
                        "  ],\n"
                        "  \"edges\": [\n"
                        "    {\"source\": \"TermID\", \"target\": \"TermID\", \"weight\": å…±ç¾å¼·åº¦ (1-5), \"note\": \"é—œè¯èªªæ˜\"},\n"
                        "    ...\n"
                        "  ]\n"
                        "}\n"
                        "åªè¼¸å‡º JSONï¼Œä¸è¦é¡å¤–æ–‡å­—ã€‚"
                    )
                    user_prompt = base_text
                    raw = call_llm(
                        provider=provider,
                        model=model,
                        system_prompt=system_prompt,
                        user_prompt=user_prompt,
                        max_tokens=1024,
                        temperature=0.4,
                    )
                    raw_str = raw.strip().strip("```json").strip("```").strip()
                    st.session_state.note_wordgraph_json_text = raw_str
                    add_combat_log("å·²ç”¢ç”Ÿè©å½™é—œè¯åœ– JSON çµæ§‹ã€‚", "success")
                except Exception as e:
                    st.error(f"è©å½™é—œè¯ JSON ç”¢ç”Ÿå¤±æ•—ï¼š{e}")
        
        wordgraph_text = st.text_area(
            "è©å½™é—œè¯åœ– JSON å¯æ–¼æ­¤èª¿æ•´å¾Œé‡æ–°ç¹ªè£½",
            value=st.session_state.note_wordgraph_json_text,
            height=220,
        )
        if st.button("ğŸ“Š æ ¹æ“š JSON é¡¯ç¤ºè©å½™é—œè¯åœ–", use_container_width=True):
            try:
                data = json.loads(wordgraph_text)
                nodes = data.get("nodes", [])
                edges = data.get("edges", [])
                dot = "graph G {\n"
                # ç¯€é»ï¼ˆä»¥é »ç‡æ§åˆ¶å¤§å°ï¼‰
                for n in nodes:
                    nid = n.get("id", "")
                    label = n.get("label", nid)
                    freq = n.get("frequency", 1)
                    size = 10 + freq * 2
                    dot += f"  \"{nid}\" [label=\"{label}\", fontsize={size}];\n"
                # ç„¡å‘é‚Š
                for e in edges:
                    src = e.get("source", "")
                    tgt = e.get("target", "")
                    w = e.get("weight", 1)
                    note = e.get("note", "")
                    penwidth = 1 + w
                    dot += (
                        f"  \"{src}\" -- \"{tgt}\" "
                        f"[label=\"{note}\", penwidth={penwidth}];\n"
                    )
                dot += "}"
                st.graphviz_chart(dot)
            except Exception as e:
                st.error(f"è§£ææˆ–ç¹ªè£½è©å½™é—œè¯åœ–æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

# -----------------------------------------------------------
# Dashboard Tab
# -----------------------------------------------------------

def render_dashboard_tab():
    """Render interactive dashboard"""
    st.markdown(f"## ğŸ“Š {get_translation('dashboard')}")
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("å¯©æŸ¥æˆç†Ÿåº¦ç­‰ç´š", st.session_state.player_level)
    with col2:
        st.metric("å·²å®Œæˆæ¡ˆä»¶æ•¸", st.session_state.quests_completed)
    with col3:
        st.metric("LLM å‘¼å«æ¬¡æ•¸", len(st.session_state.combat_log))
    with col4:
        st.metric("å·²åŸ·è¡Œæµç¨‹æ•¸", len(st.session_state.pipeline_history))
    
    st.markdown("---")
    
    dash_tab1, dash_tab2, dash_tab3 = st.tabs(["æ¡ˆä»¶æ­·ç¨‹", "æ´»å‹•ç´€éŒ„", "é‡Œç¨‹ç¢‘"])
    
    with dash_tab1:
        st.markdown("### ğŸ“ æ¡ˆä»¶ / æµç¨‹æ­·ç¨‹")
        history = st.session_state.get("pipeline_history", [])
        if not history:
            st.info("å°šæœªåŸ·è¡Œä»»ä½•å¯©æŸ¥æµç¨‹ã€‚")
        else:
            for run_idx, run in enumerate(reversed(history), start=1):
                with st.expander(f"æ¡ˆä»¶æµç¨‹ #{len(history) - run_idx + 1}"):
                    for step_idx, item in enumerate(run, start=1):
                        st.markdown(f"**æ­¥é©Ÿ {step_idx}** â€“ ä»£ç† `{item['agent_id']}`")
                        st.markdown(item["output"][:300] + "...")
    
    with dash_tab2:
        st.markdown("### ğŸ“‘ å®Œæ•´æ´»å‹•ç´€éŒ„")
        if st.session_state.combat_log:
            for entry in reversed(st.session_state.combat_log):
                st.markdown(f"{entry['icon']} {entry['message']}")
        else:
            st.info("å°šç„¡æ´»å‹•ç´€éŒ„ã€‚")
    
    with dash_tab3:
        st.markdown("### ğŸ… å¯©æŸ¥é‡Œç¨‹ç¢‘")
        
        achievements = []
        if st.session_state.player_level >= 5:
            achievements.append("ğŸ–ï¸ é€²éšå¯©æŸ¥å®˜ï¼šå¯©æŸ¥æˆç†Ÿåº¦ç­‰ç´šé” 5ã€‚")
        if st.session_state.quests_completed >= 10:
            achievements.append("ğŸ“œ æ¡ˆä»¶é”äººï¼šå®Œæˆ 10 ä»¶ä»¥ä¸Šæ¡ˆä»¶æµç¨‹ã€‚")
        if len(st.session_state.combat_log) >= 50:
            achievements.append("ğŸ“ˆ é«˜åº¦äº’å‹•ï¼šå·²åŸ·è¡Œè¶…é 50 æ¬¡æ¨¡å‹å‘¼å«æˆ–æ“ä½œã€‚")
        if st.session_state.player_level >= 10:
            achievements.append("ğŸ‘‘ è³‡æ·±å¯©æŸ¥æ¶æ§‹å¸«ï¼šå¯©æŸ¥æˆç†Ÿåº¦ç­‰ç´šé” 10ã€‚")
        
        if achievements:
            for ach in achievements:
                st.success(ach)
        else:
            st.info("æŒçºŒç´¯ç©æ¡ˆä»¶èˆ‡æµç¨‹ï¼Œå¯è§£é–æ›´å¤šå¯©æŸ¥é‡Œç¨‹ç¢‘ã€‚")

# -----------------------------------------------------------
# Main Entry Point
# -----------------------------------------------------------

def main():
    """Main application entry point"""
    st.set_page_config(
        page_title="FDA 510(k) Multi-Agent Review Studio",
        page_icon="ğŸ¥",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    init_session_state()
    apply_custom_css()
    config = load_agents_config()
    render_enhanced_sidebar(config)
    
    st.markdown(f"# ğŸ¥ {get_translation('title')}")
    st.markdown(f"_{get_translation('subtitle')}_")
    
    render_review_context_selector()
    
    st.markdown("---")
    
    tab_input, tab_pipeline, tab_smart, tab_notes, tab_dashboard = st.tabs([
        f"ğŸ“ {get_translation('input')}",
        f"ğŸ”„ {get_translation('pipeline')}",
        f"âœ¨ {get_translation('smart_replace')}",
        f"ğŸ“” {get_translation('notes')}",
        f"ğŸ“Š {get_translation('dashboard')}",
    ])
    
    with tab_input:
        render_input_tab()
    
    with tab_pipeline:
        render_pipeline_tab(config)
    
    with tab_smart:
        render_smart_replace_tab()
    
    with tab_notes:
        render_notes_tab()
    
    with tab_dashboard:
        render_dashboard_tab()

if __name__ == "__main__":
    main()